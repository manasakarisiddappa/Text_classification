{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Importing all the needed modules.\n",
    "import os\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns\n",
    "import zlib\n",
    "import itertools\n",
    "import sklearn\n",
    "import itertools\n",
    "import scipy\n",
    "import skimage\n",
    "from skimage.transform import resize\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, StratifiedKFold, GridSearchCV\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import confusion_matrix, make_scorer, accuracy_score, classification_report\n",
    "import keras\n",
    "from keras.layers import Embedding,Dense, Dropout, Activation, Flatten, Conv1D,Conv2D,MaxPooling1D,Concatenate, MaxPooling2D, Lambda, MaxPool2D, BatchNormalization\n",
    "from keras.utils import np_utils\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import models, layers, optimizers\n",
    "from keras.engine.input_layer import Input\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.utils import class_weight\n",
    "from keras.optimizers import SGD, RMSprop, Adam, Adagrad, Adadelta, RMSprop\n",
    "from keras.models import Sequential, model_from_json\n",
    "from keras.layers import Activation,Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
    "from keras.layers import MaxPooling2D,AveragePooling2D, GlobalAveragePooling2D,BatchNormalization\n",
    "from keras.preprocessing.image import array_to_img, img_to_array, load_img, ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "from keras import backend as K\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.models import Model\n",
    "from keras.applications.mobilenet import MobileNet\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.555)\n",
    "\n",
    "sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mDMgSstPYv0P"
   },
   "source": [
    "# Text Classification:\n",
    "\n",
    "## Data\n",
    "<pre>\n",
    "1. we have total of 20 types of documents(Text files) and total 18828 documents(text files).\n",
    "2. You can download data from this <a href='https://drive.google.com/open?id=1rxD15nyeIPIAZ-J2VYPrDRZI66-TBWvM'>link</a>, in that you will get documents.rar folder. <br>If you unzip that, you will get total of 18828 documnets. document name is defined as'ClassLabel_DocumentNumberInThatLabel'. \n",
    "so from document name, you can extract the label for that document.\n",
    "4. Now our problem is to classify all the documents into any one of the class. \n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KAR5HoR1Yv0m"
   },
   "source": [
    "### Preprocessing:\n",
    "<pre>\n",
    "useful links: <a href='http://www.pyregex.com/'>http://www.pyregex.com/</a>\n",
    "\n",
    "<font color='blue'><b>1.</b></font> Find all emails in the document and then get the text after the \"@\". and then split those texts by '.' \n",
    "after that remove the words whose length is less than or equal to 2 and also remove'com' word and then combine those words by space. \n",
    "In one doc, if we have 2 or more mails, get all.\n",
    "<b>Eg:[test@dm1.d.com, test2@dm2.dm3.com]-->[dm1.d.com, dm3.dm4.com]-->[dm1,d,com,dm2,dm3,com]-->[dm1,dm2,dm3]-->\"dm1 dm2 dm3\" </b> \n",
    "append all those into one list/array. ( This will give length of 18828 sentences i.e one list for each of the document). \n",
    "Some sample output was shown below. \n",
    "\n",
    "> In the above sample document there are emails [jcopelan@nyx.cs.du.edu, 65882@mimsy.umd.edu, mangoe@cs.umd.edu]\n",
    "\n",
    "preprocessing:\n",
    "[jcopelan@nyx.cs.du.edu, 65882@mimsy.umd.edu, mangoe@cs.umd.edu] ==> [nyx cs du edu mimsy umd edu cs umd edu] ==> \n",
    "[nyx edu mimsy umd edu umd edu]\n",
    "\n",
    "<font color='blue'><b>2.</b></font> Replace all the emails by space in the original text. \n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import nltk\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "files = glob.glob(\"documents/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18828"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hpuerca atl 18380 18380 18380\n"
     ]
    }
   ],
   "source": [
    "final = []; cread = 0; label = []; mlen = 0; idx = 0; subj = []; orgtxt = []\n",
    "for enm,doc in enumerate(files):\n",
    "    try:\n",
    "        f = open(doc,'r', encoding='utf8')\n",
    "        content = f.read()\n",
    "    \n",
    "    \n",
    "        soup = BeautifulSoup(content)\n",
    "        text = soup.get_text()\n",
    "        p1 = re.findall(r'[a-zA-Z0-9-]+[a-zA-Z0-9-\\.]*@([a-zA-Z0-9-]+[a-zA-Z0-9-\\.]*)', text)\n",
    "        otxt = re.sub(r'[a-zA-Z0-9-]+[a-zA-Z0-9-\\.]*@([a-zA-Z0-9-]+[a-zA-Z0-9-\\.]*)',\"\",text)\n",
    "        em = \"\"\n",
    "        for each in p1:\n",
    "            for word in each.split('.'):\n",
    "                if len(word) > 2 and word != 'com':\n",
    "                    em += word\n",
    "                    em += \" \"\n",
    "\n",
    "        if len(em) > 2:\n",
    "            label.append(doc.split('/')[1].split('_')[0])\n",
    "            final.append(em[:-1].lower())\n",
    "            if len(em[:-1]) > mlen:\n",
    "                mlen = len(em)\n",
    "                idx = enm\n",
    "\n",
    "            txt = re.findall(r'Subject\\:[ Re\\:]*([A-Za-z0-9\\:\\(\\)\\! ]*)', text)\n",
    "            otxt = re.sub(r'Subject\\:[ Re\\:]*([A-Za-z0-9\\:\\(\\)\\! ]*)',\"\",otxt)\n",
    "            sub = \"\"\n",
    "            for each in txt:\n",
    "                sub += re.sub(r\"[-()\\\"#/@;:<>{}`+=~|.!?,]\", \"\",each)\n",
    "            subj.append(sub)\n",
    "            orgtxt.append(otxt)\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "print(final[0],len(final),len(label),len(subj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18380"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "body = []\n",
    "for tmp in orgtxt:\n",
    "    tmp = re.sub(r'From\\:[ Re\\:]*([A-Za-z0-9\\:\\(\\)\\!\\. ]*)',\"\", tmp)\n",
    "    tmp = re.sub(r'Write to\\:[ Re\\:]*([A-Za-z0-9\\:\\(\\)\\!\\. ]*)',\"\", tmp)\n",
    "    tmp = re.sub(r'\\([A-Za-z0-9\\:\\!\\.\\-\\,\\;\\'\\`\\n\\t\\?\\/\\>\\<\\$ ]*\\)',\"\", tmp)\n",
    "    tmp = re.sub(r'\\<[A-Za-z0-9\\:\\!\\.\\-\\,\\;\\'\\`\\n\\t\\?\\/ ]*\\>',\"\", tmp)\n",
    "    tmp = re.sub(r'[\\n\\t\\-\\\\\\/\\|]',\" \",tmp)\n",
    "    text = re.sub(r'[A-Za-z0-9]*\\:',\"\",tmp)\n",
    "\n",
    "    parse_tree = nltk.ne_chunk(nltk.tag.pos_tag(text.split()), binary=True) \n",
    "    ctxt = \"\"\n",
    "    chunk = list(parse_tree)\n",
    "\n",
    "    for each in chunk:\n",
    "        if isinstance(each, nltk.tree.Tree):\n",
    "            ctxt += '_'.join(k[0] for k in each)\n",
    "            ctxt += ' '\n",
    "        else:\n",
    "            ctxt += each[0]+' '\n",
    "\n",
    "    text = ctxt.lower()\n",
    "    text = re.sub(r\"i'm\", \"i am\", text)\n",
    "    text = re.sub(r\"he's\", \"he is\", text)\n",
    "    text = re.sub(r\"she's\", \"she is\", text)\n",
    "    text = re.sub(r\"it's\", \"it is\", text)\n",
    "    text = re.sub(r\"that's\", \"that is\", text)\n",
    "    text = re.sub(r\"what's\", \"that is\", text)\n",
    "    text = re.sub(r\"where's\", \"where is\", text)\n",
    "    text = re.sub(r\"how's\", \"how is\", text)\n",
    "    text = re.sub(r\"'s\", \" is\", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will\", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have\", text)\n",
    "    text = re.sub(r\"\\'re\", \" are\", text)\n",
    "    text = re.sub(r\"\\'d\", \" would\", text)\n",
    "    text = re.sub(r\"\\'re\", \" are\", text)\n",
    "    text = re.sub(r\"won't\", \"will not\", text)\n",
    "    text = re.sub(r\"can't\", \"can not\", text)\n",
    "    text = re.sub(r\"n't\", \" not\", text)\n",
    "    text = re.sub(r\"n'\", \"ng\", text)\n",
    "    text = re.sub(r\"'bout\", \"about\", text)\n",
    "    text = re.sub(r\"'til\", \"until\", text)\n",
    "    text = re.sub(r\"[0-9]\", \"\", text)\n",
    "    text = re.sub(r\" [a-zA-Z]\\_\", \" \", text)\n",
    "    text = re.sub(r\" [a-zA-Z][a-zA-Z]\\_\", \" \", text)\n",
    "    text = re.sub(r\"[-()\\\"#/@;:<>{}`+=~|.!?,$%^&*'/+\\[\\]]+\", \"\", text)\n",
    "    text = re.sub(r\"\\b[a-zA-Z]{1,2}\\b\", \"\", text)\n",
    "    text = re.sub(r\"\\b[a-zA-Z]{15,}\\b\", \"\", text)\n",
    "    text = re.sub(r' _',\" \", text)\n",
    "    text = re.sub(r'_ ',\" \", text)\n",
    "    text = re.sub(r'__+',\" \", text)\n",
    "    text = re.sub(r\" +\", \" \", text)\n",
    "    body.append(text)\n",
    "\n",
    "len(body)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zIovFDQzYv03"
   },
   "source": [
    "<pre>\n",
    "<font color='blue'><b>3.</b></font> Get subject of the text i.e. get the total lines where \"Subject:\" occur and remove \n",
    "the word which are before the \":\" remove the newlines, tabs, punctuations, any special chars.\n",
    "<b>Eg: if we have sentance like \"Subject: Re: Gospel Dating @ \\r\\r\\n\" --> You have to get \"Gospel Dating\"</b> \n",
    "Save all this data into another list/array. \n",
    "\n",
    "<font color='blue'><b>4.</b></font> After you store it in the list, Replace those sentances in original text by space.\n",
    "\n",
    "<font color='blue'><b>5.</b></font> Delete all the sentances where sentence starts with <b>\"Write to:\"</b> or <b>\"From:\"</b>.\n",
    "> In the above sample document check the 2nd line, we should remove that\n",
    "\n",
    "<font color='blue'><b>6.</b></font> Delete all the tags like \"< anyword >\"\n",
    "> In the above sample document check the 4nd line, we should remove that \"< 65882@mimsy.umd.edu >\"\n",
    "\n",
    "\n",
    "<font color='blue'><b>7.</b></font> Delete all the data which are present in the brackets. \n",
    "In many text data, we observed that, they maintained the explanation of sentence \n",
    "or translation of sentence to another language in brackets so remove all those.\n",
    "<b>Eg: \"AAIC-The course that gets you HIRED(AAIC - Der Kurs, der Sie anstellt)\" --> \"AAIC-The course that gets you HIRED\"</b>\n",
    "\n",
    "> In the above sample document check the 4nd line, we should remove that \"(Charley Wingate)\"\n",
    "\n",
    "\n",
    "<font color='blue'><b>8.</b></font> Remove all the newlines('\\n'), tabs('\\t'), \"-\", \"\\\".\n",
    "\n",
    "<font color='blue'><b>9.</b></font> Remove all the words which ends with <b>\":\"</b>.\n",
    "<b>Eg: \"Anyword:\"</b>\n",
    "> In the above sample document check the 4nd line, we should remove that \"writes:\"\n",
    "\n",
    "\n",
    "<font color='blue'><b>10.</b></font> Decontractions, replace words like below to full words. \n",
    "please check the donors choose preprocessing for this \n",
    "<b>Eg: can't -> can not, 's -> is, i've -> i have, i'm -> i am, you're -> you are, i'll --> i will </b>\n",
    "\n",
    "<b> There is no order to do point 6 to 10. but you have to get final output correctly</b>\n",
    "\n",
    "<font color='blue'><b>11.</b></font> Do chunking on the text you have after above preprocessing. \n",
    "Text chunking, also referred to as shallow parsing, is a task that \n",
    "follows Part-Of-Speech Tagging and that adds more structure to the sentence.\n",
    "So it combines the some phrases, named entities into single word.\n",
    "So after that combine all those phrases/named entities by separating <b>\"_\"</b>. \n",
    "And remove the phrases/named entities if that is a \"Person\". \n",
    "You can use <b>nltk.ne_chunk</b> to get these. \n",
    "Below we have given one example. please go through it. \n",
    "\n",
    "useful links: \n",
    "<a href='https://www.nltk.org/book/ch07.html'>https://www.nltk.org/book/ch07.html</a>\n",
    "<a href='https://stackoverflow.com/a/31837224/4084039'>https://stackoverflow.com/a/31837224/4084039</a>\n",
    "<a href='http://www.nltk.org/howto/tree.html'>http://www.nltk.org/howto/tree.html</a>\n",
    "<a href='https://stackoverflow.com/a/44294377/4084039'>https://stackoverflow.com/a/44294377/4084039</a>\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2lAaKQ6EYv04",
    "outputId": "53b66a94-acef-4002-e51c-002bde4178b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i am living in the New York --> [('i', 'NN'), ('am', 'VBP'), ('living', 'VBG'), ('in', 'IN'), ('the', 'DT'), Tree('GPE', [('New', 'NNP'), ('York', 'NNP')])]\n",
      " \n",
      "--------------------------------------------------\n",
      " \n",
      "My name is Srikanth Varma --> [('My', 'PRP$'), ('name', 'NN'), ('is', 'VBZ'), Tree('PERSON', [('Srikanth', 'NNP'), ('Varma', 'NNP')])]\n"
     ]
    }
   ],
   "source": [
    "#i am living in the New York\n",
    "print(\"i am living in the New York -->\", list(chunks))\n",
    "print(\" \")\n",
    "print(\"-\"*50)\n",
    "print(\" \")\n",
    "#My name is Srikanth Varma\n",
    "print(\"My name is Srikanth Varma -->\", list(chunks1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XV8gzLUjYv0-"
   },
   "source": [
    "<pre>We did chunking for above two lines and then We got one list where each word is mapped to a \n",
    "POS(parts of speech) and also if you see \"New York\" and \"Srikanth Varma\", \n",
    "they got combined and represented as a tree and \"New York\" was referred as \"GPE\" and \"Srikanth Varma\" was referred as \"PERSON\". \n",
    "so now you have to Combine the \"New York\" with <b>\"_\"</b> i.e \"New_York\"\n",
    "and remove the \"Srikanth Varma\" from the above sentence because it is a person.</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VpaC-KF3Yv1A"
   },
   "source": [
    "<pre>\n",
    "<font color='blue'><b>13.</b></font> Replace all the digits with space i.e delete all the digits. \n",
    "> In the above sample document, the 6th line have digit 100, so we have to remove that.\n",
    "\n",
    "<font color='blue'><b>14.</b></font> After doing above points, we observed there might be few word's like\n",
    " <b> \"_word_\" (i.e starting and ending with the _), \"_word\" (i.e starting with the _),\n",
    "  \"word_\" (i.e ending with the _)</b> remove the <b>_</b> from these type of words. \n",
    "\n",
    "<font color='blue'><b>15.</b></font>  We also observed some words like <b> \"OneLetter_word\"- eg: d_berlin, \n",
    "\"TwoLetters_word\" - eg: dr_berlin </b>, in these words we remove the \"OneLetter_\" (d_berlin ==> berlin) and \n",
    "\"TwoLetters_\" (de_berlin ==> berlin). i.e remove the words \n",
    "which are length less than or equal to 2 after spliiting those words by \"_\". \n",
    "\n",
    "<font color='blue'><b>16.</b></font> Convert all the words into lower case and lowe case \n",
    "and remove the words which are greater than or equal to 15 or less than or equal to 2.\n",
    "\n",
    "<font color='blue'><b>17.</b></font> replace all the words except \"A-Za-z_\" with space. \n",
    "\n",
    "<font color='blue'><b>18.</b></font> Now You got Preprocessed Text, email, subject. create a dataframe with those. \n",
    "Below are the columns of the df. \n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18380, 18380, 18380, 18380)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final),len(subj),len(body),len(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18380"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = []\n",
    "for a,b,c in zip(final,subj,body):\n",
    "    data.append(a+\" \"+b.lower()+\" \"+c)\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wmich edu lab wmich edu prk referral in canada could some please refer someone who can perform prk canada have looked the yellow pages with little success and someone has had good experience that would especially helpful you could please let know thanks kurt hozak '"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hpuerca atl super mega automobile sightings ex...</td>\n",
       "      <td>rec.autos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wmich edu lab wmich edu prk referral in canada...</td>\n",
       "      <td>sci.med</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>netcom cats ucsc edu netcom help duo 230 probl...</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ulkyvx louisville edu camelot bradley edu and ...</td>\n",
       "      <td>rec.sport.baseball</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gauss med harvard edu sol ctr columbia edu sta...</td>\n",
       "      <td>rec.sport.hockey</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text                  label\n",
       "0  hpuerca atl super mega automobile sightings ex...              rec.autos\n",
       "1  wmich edu lab wmich edu prk referral in canada...                sci.med\n",
       "2  netcom cats ucsc edu netcom help duo 230 probl...  comp.sys.mac.hardware\n",
       "3  ulkyvx louisville edu camelot bradley edu and ...     rec.sport.baseball\n",
       "4  gauss med harvard edu sol ctr columbia edu sta...       rec.sport.hockey"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(data, columns = ['text']) \n",
    "df['label'] = label\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n3ucJLtWYv1V"
   },
   "source": [
    "### Training The models to Classify: \n",
    "\n",
    "<pre>\n",
    "1. Combine \"preprocessed_text\", \"preprocessed_subject\", \"preprocessed_emails\" into one column. use that column to model. \n",
    "\n",
    "2. Now Split the data into Train and test. use 25% for test also do a stratify split. \n",
    "\n",
    "3. Analyze your text data and pad the sequnce if required. \n",
    "Sequnce length is not restricted, you can use anything of your choice. \n",
    "you need to give the reasoning\n",
    "\n",
    "4. Do Tokenizer i.e convert text into numbers. please be careful while doing it. \n",
    "if you are using tf.keras \"Tokenizer\" API, it removes the <b>\"_\"</b>, but we need that.\n",
    "\n",
    "5. code the model's ( Model-1, Model-2 ) as discussed below \n",
    "and try to optimize that models.  \n",
    "\n",
    "6. For every model use predefined Glove vectors. \n",
    "<b>Don't train any word vectors while Training the model.</b>\n",
    "\n",
    "7. Use \"categorical_crossentropy\" as Loss. \n",
    "\n",
    "8. Use <b>Accuracy and Micro Avgeraged F1 score</b> as your as Key metrics to evaluate your model. \n",
    "\n",
    "9.  Use Tensorboard to plot the loss and Metrics based on the epoches.\n",
    "\n",
    "10. Please save your best model weights in to <b>'best_model_L.h5' ( L = 1 or 2 )</b>. \n",
    "\n",
    "11. You are free to choose any Activation function, learning rate, optimizer.\n",
    "But have to use the same architecture which we are giving below.\n",
    "\n",
    "12. You can add some layer to our architecture but you <b>deletion</b> of layer is not acceptable.\n",
    "\n",
    "13. Try to use <b>Early Stopping</b> technique or any of the callback techniques that you did in the previous assignments.\n",
    "\n",
    "14. For Every model save your model to image ( Plot the model) with shapes \n",
    "and inlcude those images in the notebook markdown cell, \n",
    "upload those imgages to Classroom. You can use \"plot_model\" \n",
    "please refer <a href='https://www.tensorflow.org/api_docs/python/tf/keras/utils/plot_model'>this</a> if you don't know how to plot the model with shapes. \n",
    "\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data splitting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13785 4595 13785 4595\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['text'], df['label'], test_size=0.25, random_state=42, stratify = label)\n",
    "print(len(X_train),len(X_test),len(y_train),len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.79770060e-04, 3.26854654e-04, 6.37366575e-04, 1.20936222e-03,\n",
       "        2.35335351e-03, 4.52693696e-03, 8.64530559e-03, 1.41364638e-02,\n",
       "        2.22424592e-02, 3.27835218e-02, 4.94857946e-02, 7.36893817e-02,\n",
       "        1.11718921e-01, 2.18535022e-01, 1.17195370e+00]),\n",
       " array([1.07874996, 1.66271741, 2.24668486, 2.83065231, 3.41461975,\n",
       "        3.9985872 , 4.58255465, 5.1665221 , 5.75048955, 6.33445699,\n",
       "        6.91842444, 7.50239189, 8.08635934, 8.67032679, 9.25429423,\n",
       "        9.83826168]),\n",
       " <a list of 15 Patch objects>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "plt.hist(vectorizer.idf_, normed=True, bins=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc = []\n",
    "for word,idx in vectorizer.vocabulary_.items():\n",
    "    if vectorizer.idf_[idx] >= 9.3:\n",
    "        voc.append(word)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71711"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(voc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "MAX_LEN = 1000\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(voc)\n",
    "seq_train = tokenizer.texts_to_sequences(X_train)\n",
    "seq_test = tokenizer.texts_to_sequences(X_test)\n",
    "dictionary = tokenizer.word_index\n",
    "\n",
    "word2idx = {}\n",
    "idx2word = {}\n",
    "for k, v in dictionary.items(): \n",
    "    word2idx[k] = v\n",
    "    idx2word[v] = k\n",
    "\n",
    "input_data_train = pad_sequences(seq_train, maxlen=MAX_LEN, dtype='int32', padding='post', truncating='post')\n",
    "input_data_test = pad_sequences(seq_test, maxlen=MAX_LEN, dtype='int32', padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "def glove_100d_dictionary(GLOVE_DIR):\n",
    "    embeddings_index = {}\n",
    "    f = open(os.path.join(GLOVE_DIR, 'glove.6B.100d.txt'))\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "    f.close()\n",
    "    return embeddings_index\n",
    "\n",
    "emd_ind = glove_100d_dictionary(\"GLOVE_DIR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69410"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(69411, 100)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def embedding_matrix_creater(embedding_dimention):\n",
    "    embedding_matrix = np.zeros((len(word2idx) + 1, embedding_dimention))\n",
    "    for word, i in word2idx.items():\n",
    "        embedding_vector = emd_ind.get(word)\n",
    "        if embedding_vector is not None:\n",
    "          # words not found in embedding index will be all-zeros.\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "    return embedding_matrix\n",
    "\n",
    "emd_mat = embedding_matrix_creater(100)\n",
    "emd_mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13785, 4595)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "import tensorflow as tf\n",
    "\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "lnum_tr = label_encoder.fit_transform(y_train)\n",
    "lnum_te = label_encoder.transform(y_test)\n",
    "\n",
    "lab_train = tf.keras.utils.to_categorical(lnum_tr,dtype='float32')\n",
    "lab_test = tf.keras.utils.to_categorical(lnum_te,dtype='float32')\n",
    "len(lab_train),len(lab_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 69411\n",
    "EMBEDDING_DIM = 100\n",
    "MAX_LEN = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_layer(filters,kernel):\n",
    "    return Conv1D(filters,kernel,activation = 'relu',kernel_initializer=\"he_normal\",kernel_regularizer=keras.regularizers.l2(0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_18 (InputLayer)           (None, 1000)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_18 (Embedding)        (None, 1000, 100)    6941100     input_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_171 (Conv1D)             (None, 996, 64)      32064       embedding_18[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_172 (Conv1D)             (None, 996, 64)      32064       embedding_18[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_173 (Conv1D)             (None, 996, 64)      32064       embedding_18[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_52 (Concatenate)    (None, 996, 192)     0           conv1d_171[0][0]                 \n",
      "                                                                 conv1d_172[0][0]                 \n",
      "                                                                 conv1d_173[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_52 (MaxPooling1D) (None, 199, 192)     0           concatenate_52[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_174 (Conv1D)             (None, 195, 16)      15376       max_pooling1d_52[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_175 (Conv1D)             (None, 195, 64)      61504       max_pooling1d_52[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_176 (Conv1D)             (None, 195, 32)      30752       max_pooling1d_52[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_53 (Concatenate)    (None, 195, 112)     0           conv1d_174[0][0]                 \n",
      "                                                                 conv1d_175[0][0]                 \n",
      "                                                                 conv1d_176[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_53 (MaxPooling1D) (None, 39, 112)      0           concatenate_53[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_180 (Conv1D)             (None, 35, 32)       17952       max_pooling1d_53[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_18 (Flatten)            (None, 1120)         0           conv1d_180[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_35 (Dropout)            (None, 1120)         0           flatten_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_35 (Dense)                (None, 128)          143488      dropout_35[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_36 (Dense)                (None, 20)           2580        dense_35[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 7,308,944\n",
      "Trainable params: 367,844\n",
      "Non-trainable params: 6,941,100\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder_inputs = Input(shape=(MAX_LEN, ), dtype='int32',)\n",
    "embedding_layer = Embedding(input_dim = VOCAB_SIZE, output_dim = EMBEDDING_DIM,input_length = MAX_LEN, \n",
    "                            weights = [emd_mat],trainable = False)(encoder_inputs)\n",
    "c1 = conv_layer(64,5)(embedding_layer)\n",
    "c2 = conv_layer(64,5)(embedding_layer)\n",
    "c3 = conv_layer(64,5)(embedding_layer)\n",
    "con = Concatenate()([c1,c2,c3])\n",
    "pool = MaxPooling1D(5)(con)\n",
    "\n",
    "c4 = conv_layer(16,5)(pool)\n",
    "c5 = conv_layer(64,5)(pool)\n",
    "c6 = conv_layer(32,5)(pool)\n",
    "con2 = Concatenate()([c4,c5,c6])\n",
    "pool2 = MaxPooling1D(5)(con2)\n",
    "\n",
    "c7 = conv_layer(16,5)(pool2)\n",
    "c8 = conv_layer(64,5)(pool2)\n",
    "c9 = conv_layer(32,5)(pool2)\n",
    "con3 = Concatenate()([c7,c8,c9])\n",
    "pool3 = MaxPooling1D(5)(con3)\n",
    "\n",
    "c7 = conv_layer(32,5)(pool2)\n",
    "flat = Flatten()(c7)\n",
    "drop = Dropout(0.3)(flat)\n",
    "d1 = Dense(128,activation='tanh')(drop)\n",
    "drop2 = Dropout(0.2)(d1)\n",
    "out = Dense(20,activation='softmax')(d1)\n",
    "model = Model(encoder_inputs,out)\n",
    "model.summary()\n",
    "model.compile(loss=keras.losses.categorical_crossentropy, \n",
    "              optimizer=keras.optimizers.Adam(0.001),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath=\"weights_email.h5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                 np.unique(lnum_tr),\n",
    "                                                 lnum_tr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 13785 samples, validate on 4595 samples\n",
      "Epoch 1/30\n",
      "13785/13785 [==============================] - 13s 962us/step - loss: 3.4490 - acc: 0.1719 - val_loss: 2.1557 - val_acc: 0.2890\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.28901, saving model to weights_email.h5\n",
      "Epoch 2/30\n",
      "13785/13785 [==============================] - 10s 707us/step - loss: 2.0753 - acc: 0.3238 - val_loss: 1.8696 - val_acc: 0.3939\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.28901 to 0.39391, saving model to weights_email.h5\n",
      "Epoch 3/30\n",
      "13785/13785 [==============================] - 8s 606us/step - loss: 1.7841 - acc: 0.4398 - val_loss: 1.6461 - val_acc: 0.4940\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.39391 to 0.49402, saving model to weights_email.h5\n",
      "Epoch 4/30\n",
      "13785/13785 [==============================] - 10s 701us/step - loss: 1.6330 - acc: 0.5151 - val_loss: 1.5964 - val_acc: 0.5375\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.49402 to 0.53754, saving model to weights_email.h5\n",
      "Epoch 5/30\n",
      "13785/13785 [==============================] - 8s 613us/step - loss: 1.5236 - acc: 0.5734 - val_loss: 1.4759 - val_acc: 0.5922\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.53754 to 0.59217, saving model to weights_email.h5\n",
      "Epoch 6/30\n",
      "13785/13785 [==============================] - 9s 638us/step - loss: 1.4495 - acc: 0.6021 - val_loss: 1.4317 - val_acc: 0.6155\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.59217 to 0.61545, saving model to weights_email.h5\n",
      "Epoch 7/30\n",
      "13785/13785 [==============================] - 9s 674us/step - loss: 1.3838 - acc: 0.6254 - val_loss: 1.4345 - val_acc: 0.6183\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.61545 to 0.61828, saving model to weights_email.h5\n",
      "Epoch 8/30\n",
      "13785/13785 [==============================] - 8s 611us/step - loss: 1.3520 - acc: 0.6389 - val_loss: 1.4261 - val_acc: 0.6257\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.61828 to 0.62568, saving model to weights_email.h5\n",
      "Epoch 9/30\n",
      "13785/13785 [==============================] - 10s 692us/step - loss: 1.3005 - acc: 0.6562 - val_loss: 1.3504 - val_acc: 0.6483\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.62568 to 0.64831, saving model to weights_email.h5\n",
      "Epoch 10/30\n",
      "13785/13785 [==============================] - 8s 613us/step - loss: 1.2854 - acc: 0.6675 - val_loss: 1.3141 - val_acc: 0.6712\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.64831 to 0.67116, saving model to weights_email.h5\n",
      "Epoch 11/30\n",
      "13785/13785 [==============================] - 10s 697us/step - loss: 1.2496 - acc: 0.6817 - val_loss: 1.3896 - val_acc: 0.6461\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.67116\n",
      "Epoch 12/30\n",
      "13785/13785 [==============================] - 8s 600us/step - loss: 1.2048 - acc: 0.6955 - val_loss: 1.3771 - val_acc: 0.6651\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.67116\n",
      "Epoch 13/30\n",
      "13785/13785 [==============================] - 8s 611us/step - loss: 1.1847 - acc: 0.7047 - val_loss: 1.3211 - val_acc: 0.6625\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.67116\n",
      "Epoch 14/30\n",
      "13785/13785 [==============================] - 9s 689us/step - loss: 1.1627 - acc: 0.7128 - val_loss: 1.4003 - val_acc: 0.6583\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.67116\n",
      "Epoch 15/30\n",
      "13785/13785 [==============================] - 8s 600us/step - loss: 1.1570 - acc: 0.7140 - val_loss: 1.2952 - val_acc: 0.6873\n",
      "\n",
      "Epoch 00015: val_acc improved from 0.67116 to 0.68727, saving model to weights_email.h5\n",
      "Epoch 16/30\n",
      "13785/13785 [==============================] - 10s 705us/step - loss: 1.1409 - acc: 0.7209 - val_loss: 1.2985 - val_acc: 0.6860\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.68727\n",
      "Epoch 17/30\n",
      "13785/13785 [==============================] - 9s 622us/step - loss: 1.1213 - acc: 0.7288 - val_loss: 1.2992 - val_acc: 0.6910\n",
      "\n",
      "Epoch 00017: val_acc improved from 0.68727 to 0.69097, saving model to weights_email.h5\n",
      "Epoch 18/30\n",
      "13785/13785 [==============================] - 8s 606us/step - loss: 1.1094 - acc: 0.7370 - val_loss: 1.3519 - val_acc: 0.6797\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.69097\n",
      "Epoch 19/30\n",
      "13785/13785 [==============================] - 10s 697us/step - loss: 1.0953 - acc: 0.7395 - val_loss: 1.3932 - val_acc: 0.6635\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.69097\n",
      "Epoch 20/30\n",
      "13785/13785 [==============================] - 8s 614us/step - loss: 1.0983 - acc: 0.7445 - val_loss: 1.2737 - val_acc: 0.7040\n",
      "\n",
      "Epoch 00020: val_acc improved from 0.69097 to 0.70403, saving model to weights_email.h5\n",
      "Epoch 21/30\n",
      "13785/13785 [==============================] - 10s 701us/step - loss: 1.0611 - acc: 0.7552 - val_loss: 1.2915 - val_acc: 0.6923\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.70403\n",
      "Epoch 22/30\n",
      "13785/13785 [==============================] - 8s 602us/step - loss: 1.0524 - acc: 0.7542 - val_loss: 1.3240 - val_acc: 0.7016\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.70403\n",
      "Epoch 23/30\n",
      "13785/13785 [==============================] - 8s 609us/step - loss: 1.0531 - acc: 0.7566 - val_loss: 1.3743 - val_acc: 0.6805\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.70403\n",
      "Epoch 24/30\n",
      "13785/13785 [==============================] - 10s 694us/step - loss: 1.0417 - acc: 0.7622 - val_loss: 1.3171 - val_acc: 0.7077\n",
      "\n",
      "Epoch 00024: val_acc improved from 0.70403 to 0.70773, saving model to weights_email.h5\n",
      "Epoch 25/30\n",
      "13785/13785 [==============================] - 8s 607us/step - loss: 1.0331 - acc: 0.7652 - val_loss: 1.3161 - val_acc: 0.7018\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.70773\n",
      "Epoch 26/30\n",
      "13785/13785 [==============================] - 10s 692us/step - loss: 1.0315 - acc: 0.7713 - val_loss: 1.3284 - val_acc: 0.7032\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.70773\n",
      "Epoch 27/30\n",
      "13785/13785 [==============================] - 8s 601us/step - loss: 1.0247 - acc: 0.7727 - val_loss: 1.2886 - val_acc: 0.7217\n",
      "\n",
      "Epoch 00027: val_acc improved from 0.70773 to 0.72165, saving model to weights_email.h5\n",
      "Epoch 28/30\n",
      "13785/13785 [==============================] - 8s 615us/step - loss: 1.0210 - acc: 0.7756 - val_loss: 1.2920 - val_acc: 0.7193\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.72165\n",
      "Epoch 29/30\n",
      "13785/13785 [==============================] - 10s 694us/step - loss: 1.0088 - acc: 0.7782 - val_loss: 1.3158 - val_acc: 0.7062\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.72165\n",
      "Epoch 30/30\n",
      "13785/13785 [==============================] - 9s 617us/step - loss: 0.9932 - acc: 0.7854 - val_loss: 1.3226 - val_acc: 0.7164\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.72165\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=input_data_train, y=lab_train, batch_size=32, epochs=30, verbose=1,callbacks=callbacks_list,\n",
    "                    validation_data=(input_data_test,lab_test),class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.vis_utils import plot_model\n",
    "plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gXPPsovJ3ePk"
   },
   "source": [
    "<pre>\n",
    "<b>Encoding of the Text </b> --> For a given text data create a Matrix with Embedding layer as shown Below. \n",
    "In the example we have considered d = 5, but in this assignment we will get d = dimension of Word vectors we are using.\n",
    " i.e if we have maximum of 350 words in a sentence and embedding of 300 dim word vector, \n",
    " we result in 350*300 dimensional matrix for each sentance as output after embedding layer\n",
    "<img src='https://i.imgur.com/kiVQuk1.png'>\n",
    "Ref: https://i.imgur.com/kiVQuk1.png\n",
    "\n",
    "<b>Reference:</b>\n",
    "<a href='https://stackoverflow.com/a/43399308/4084039'>https://stackoverflow.com/a/43399308/4084039</a>\n",
    "<a href='https://missinglink.ai/guides/keras/keras-conv1d-working-1d-convolutional-neural-networks-keras/'>https://missinglink.ai/guides/keras/keras-conv1d-working-1d-convolutional-neural-networks-keras/</a>\n",
    "\n",
    "<b><a href='https://stats.stackexchange.com/questions/270546/how-does-keras-embedding-layer-work'>How EMBEDDING LAYER WORKS </a></b>\n",
    "\n",
    "</pre>\n",
    "\n",
    "### Go through this blog, if you have any doubt on using predefined Embedding values in Embedding layer - https://machinelearningmastery.com/use-word-embedding-layers-deep-learning-keras/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wGVQKge3Yv1e"
   },
   "source": [
    "<img src='https://i.imgur.com/fv1GvFJ.png'>\n",
    "ref: 'https://i.imgur.com/fv1GvFJ.png'"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Text Classification Assignment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
